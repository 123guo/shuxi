<h1> <center>数栖开发平台-帮助文档</center> </h1>

[TOC]

### 1. 平台介绍
#### 1.1 平台概述（白松）

```sql
-- drop table demo_tdm_user_complaint_position_count_d;

create table if not exists demo_tdm_user_complaint_position_count_d
(
	  user_id			bigint comment '业主ID'
	, name				string comment '业主姓名'
	, age				bigint comment '业主年龄'
	, address			string comment '业主小区'
	, city				string comment '城市'
	, position			string comment '投诉位置'
	, position_number	bigint comment '投诉次数'
)
comment '业主投诉位置次数统计'
partitioned by (ds string comment '按天分区,例如20160620')
stored as parquet;
```

<img src="images/构造输入表.png" style="zoom:100%" />



#### 1.2 基本概念（段誉）

- 任务
- 脚本
- 资源
- 函数
- 实例
- 系统参数

### 2. 开通账户（段誉）

### 3. 快速入门 (明罡)

#### 3.1获取资源

快速入门所需的学生信息如下,以txt格式存储这些信息为文件,文件名字为student_info.txt.

```Txt
1	赵晓丽	23	50
2	王明	25	60
3	王勇	22	55
4	杜孟娟	21	50
5	李志刚	22	56
6	张林静	23	51
```

这些学生信息已经上传到在Github上.[student_info.txt](https://github.com/dtwave/shuxi/blob/master/data/student/student_info.txt)

<img src="images/student_info.png" style="zoom:100%"/>

#### 3.2 上传资源

##### 3.2.1 新建资源目录

进入数栖开发平台,点击<开发中心>下的<资源开发>,右键点击资源目录,选择新建目录

<img src="images/上传资源a.png" style="zoom:100%"/>

目录名为quick_start,点击<确定>,完成目录创建.

<img src="images/上传资源b.png" style="zoom:100%" />

##### 3.2.2 新建资源

右键点击quick_start目录,选择新建资源.

<img src="images/上传资源c.png" style="zoom:100%" />

资源命名为student_info,资源类型为txt.点击添加文件

<img src="images/上传资源d.png" style="zoom:100%" />

<img src="images/上传资源e.png" style="zoom:100%" />

#### 3.3 新建表

##### 3.3.1 创建离线任务目录

在开发中心下,点击离线任务,右键点击离线任务目录,选择新建目录,新建quick_start目录.

<img src="images/新建表a.png" style="zoom:100%" />

##### 3.3.2 创建ddl与job目录

在上步我们新建的quick_start目录下,创建ddl与job目录.

<img src="images/新建表b.png" style="zoom:100%" />

创建的ddl与job目录,如下图所示:

<img src="images/新建表c.png" style="zoom:100%"/>



##### 3.3.3 创建建表任务

<img src="images/新建表d.png" style="zoom:100%" />

任务名为:ddl_quick_start_student_info,任务类型为SparkSQL.

<img src="images/新建表e.png" style="zoom:100%" />

建表语句内容如下:

```sql
-- 如果表已存在,可以删除掉.
-- drop table if exists quick_start_student_info;

-- 新建学生表
create table if not exists quick_start_student_info
(
      id		bigint comment 'ID'
	, name		string comment '姓名'
	, age		bigint comment '年龄'
	, weight	bigint comment '体重(kg)'
)
comment '学生基本信息'
row format delimited
fields terminated by'\t' 
lines terminated by'\n'
stored as textfile;
```

##### 3.3.4 点击运行,完成表创建工作.

<img src="images/新建表f.png" style="zoom:100%"/>

运行部分日志如下图所示,如果显示任务运行成功,则表示表创建成功.

<img src="images/新建表g.png" style="zoom:100%"/>

#### 3.4 导入数据

##### 3.4.1 创建导入数据任务

右键点击job目录,选择新建离线任务,任务名为:quick_start_student_info,任务类型为hive.

<img src="images/导入数据c.png" style="zoom:100%"/>

<img src="images/导入数据a.png" style="zoom:100%"/>

导入数据语句如下:

```sql
-- 导入学生信息
load data local inpath '{student_info.txt}' overwrite into table quick_start_student_info;

-- 预览数据(支持选中执行)
select * from quick_start_student_info limit 10;
```

##### 3.4.2 运行导入数据任务

此任务需要在属性配置里设置资源依赖.资源为我们前面上传的<student_info.txt>.

<img src="images/导入数据b.png" style="zoom:100%"/>

点击运行,运行日志部分如下,如果出现任务运行成功,则表示导入数据成功.

<img src="images/导入数据d.png" style="zoom:100%"/>

#### 3.5 加工数据

##### 3.5.1 创建数据加工任务

在job目录下新建任务,任务名为:quick_start_student_statistics,任务类型为SparkSQL.

<img src="images/导入数据c.png" style="zoom:100%"/>

<img src="images/加工数据a.png" style="zoom:100%"/>

加工数据语句如下:

```sql
-- 1. 查询学生基本信息
select
		 id
       , name
       , age
       , weight
from quick_start_student_info
order by age;


-- 2. 查询学生最大年龄、最小体重
select
	  max(age)
    , min(weight)
from quick_start_student_info;
```

##### 3.5.2 运行数据加工任务

<img src="images/加工数据b.png" style="zoom:100%"/>

点击运行,运行日志部分如下,如果出现任务运行成功,则表示加工数据成功.点击<运行结果1>,<运行结果2>可以看到我们加工数据获得的结果.

<img src="images/加工数据c.png" style="zoom:100%"/>





### 4. 用户手册

#### 4.1 开发中心(明罡)
##### 4.1.1 任务操作
###### 4.1.1.1 新建
###### 4.1.1.2 复制
###### 4.1.1.3 删除
###### 4.1.1.4 格式化
###### 4.1.1.5 代码检查
###### 4.1.1.6 运行

- 选中执行

###### 4.1.1.7 提交

##### 4.1.2 属性配置
###### 4.1.2.1 运行参数 

- 用户自定义参数
- 系统参数

###### 4.1.2.2 调度配置

- 正常调度
- 跨周期调度
- 暂停调度

###### 4.1.2.3 依赖配置

- 资源依赖
- 任务依赖

###### 4.1.2.4 基线配置
###### 4.1.2.5 资源组配置

##### 4.1.3 任务类型
###### 4.1.3.1 Shell
###### 4.1.3.2 DataSync
###### 4.1.3.3 Hive
###### 4.1.3.4 SparkSQL
###### 4.1.3.5 Python
###### 4.1.3.6 PySpark
###### 4.1.3.7 Spark
###### 4.1.3.8 hive2
###### 4.1.3.9 presto
###### 4.1.3.10 FlinkSQL
###### 4.1.3.11 Flink

#### 4.2 发布中心（明罡）
##### 4.2.1 创建发布包
##### 4.2.2 发布历史
- 查看
- 发布
- 撤销

#### 4.3 运维中心（明罡）
##### 4.3.1 运行总览
##### 4.3.2 离线实例
###### 4.3.2.1 展开父节点
###### 4.3.2.2 展开子节点
###### 4.3.2.3 查看运行日志
###### 4.3.2.4 查看代码
###### 4.3.2.5 终止
###### 4.3.2.6 重跑
###### 4.3.2.7 重跑下游
###### 4.3.2.8 置成功
##### 4.3.3 离线任务
###### 4.3.3.1 补数据

- 自依赖
###### 4.3.3.2 补下游

##### 4.3.4 流任务

#### 4.4 监控管理（段誉）
##### 4.4.1 基线管理
###### 4.4.1.1 新建基线
###### 4.4.1.2 编辑基线
###### 4.4.1.3 删除基线
##### 4.4.2 基线告警
##### 4.4.3 数据质量告警

#### 4.5 数据管理（段誉）
##### 4.5.1 全局预览
##### 4.5.2 元数据管理
###### 4.5.2.1 生命周期
###### 4.5.2.2 数据血缘
##### 4.5.3 数据质量
##### 4.5.4 数据目录
###### 4.5.4.1 数据类目
###### 4.5.4.2 标签类目
##### 4.5.6 术语项管理

#### 4.6 项目管理（白松）
##### 4.6.1 项目配置
##### 4.6.2 成员管理
##### 4.6.3 资源组管理
##### 4.6.4 计算引擎管理
###### 4.6.4.1 离线引擎
###### 4.6.4.2 即席引擎
##### 4.6.6 数据源管理

#### 4.7 高级功能
##### 4.7.1 部署方案
###### 4.7.1.1 公有云
###### 4.7.1.2 私有云
###### 4.7.1.3 混合云

- 技术方案
- 部署实施

##### 4.7.2 新建项目空间

- 新建项目
- 添加资源组
- 配置计算引擎

### 4. 案例实战（明罡）
#### 4.1 背景介绍
#### 4.2 数据开发流程介绍
#### 4.3 开发
##### 4.3.1 DIM层
##### 4.3.2 ODS层
##### 4.3.3 DWD层
##### 4.3.4 TDM层
##### 4.3.5 ADM层
##### 4.3.6 配置基线
#### 4.4 发布
#### 4.5 运维
#### 4.6 数据管理
##### 4.6.1 配置数据质量
##### 4.6.2 配置生命周期
##### 4.6.3 查看数据血缘

### 5. 视频教程（段誉）
#### 5.1 新建项目空间
#### 5.2 新建函数
#### 5.3 新建、提交、发布任务
#### 5.4 基线管理
#### 5.5 元数据管理
#### 5.6 数据质量

### 6. 常见问题（白松）
### 7. 用户建议（白松）

### 8. Github地址（白松）